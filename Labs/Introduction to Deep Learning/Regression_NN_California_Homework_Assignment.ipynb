{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)\n",
        "\n",
        "# Neural Network Regression for California Housing Prices - Homework Assignment\n",
        "\n",
        "In this homework, you will implement a **Neural Network for regression** to predict the median value of California houses. This project will help you understand the fundamentals of neural networks applied to regression tasks.\n",
        "\n",
        "## üìå Project Overview\n",
        "- **Task**: Predict median house values in California\n",
        "- **Architecture**: Multi-layer Perceptron (MLP) for regression\n",
        "- **Dataset**: California Housing dataset (provided)\n",
        "- **Goal**: Build an accurate regression model using PyTorch\n",
        "\n",
        "## üìö Learning Objectives\n",
        "By completing this assignment, you will:\n",
        "- Understand neural networks for regression problems\n",
        "- Learn data preprocessing and feature engineering\n",
        "- Implement a custom neural network architecture\n",
        "- Practice training, validation, and evaluation\n",
        "- Learn about regression metrics and model performance\n"
      ],
      "metadata": {
        "id": "l7HB9ndhrvju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Initial Setup and Library Installation\n",
        "\n",
        "**Task**: Set up the environment and install necessary libraries."
      ],
      "metadata": {
        "id": "C48SHZ6vryH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "NPVvOUoKaouU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incase you run this notebook outside colab (where the libraries aren't already pre-installed)\n",
        "\n",
        "# %pip install torch\n",
        "# %pip install matplotlib\n",
        "# %pip install scikit-learn\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "O0OrlMrAr3JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2Ô∏è‚É£ Import Libraries and Configuration\n",
        "\n",
        "**Task**: Import all necessary libraries and set up configuration parameters.\n",
        "\n",
        "**Requirements**:\n",
        "- Import PyTorch and neural network modules\n",
        "- Import data processing libraries (pandas, sklearn)\n",
        "- Import visualization libraries\n",
        "- Set random seeds for reproducibility\n",
        "- Configure hyperparameters with reasonable values"
      ],
      "metadata": {
        "id": "j8XHLZBLr4H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "0_UyJZ3Vr5FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "BATCH_SIZE = 64          # Batch size for training\n",
        "LEARNING_RATE = 0.001    # Learning rate for optimizer\n",
        "NUM_EPOCHS = 100         # Number of training epochs\n",
        "HIDDEN_SIZE = 128        # Size of hidden layers\n",
        "NUM_HIDDEN_LAYERS = 3    # Number of hidden layers\n",
        "VALIDATION_SPLIT = 0.3   # Validation split ratio"
      ],
      "metadata": {
        "id": "f6Lz3iNTr5wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Data Loading and Exploration\n",
        "\n",
        "**Task**: Load the California housing dataset and explore its structure.\n",
        "\n",
        "**Requirements**:\n",
        "- Download and load the dataset\n",
        "- Display basic information about the data\n",
        "- Check for missing values\n",
        "- Understand the features and target variable"
      ],
      "metadata": {
        "id": "ulAL7pFAr7WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"camnugent/california-housing-prices\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "7IyCEe9Br8RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: List files in the dataset directory"
      ],
      "metadata": {
        "id": "KtyCqPVfr9op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Load the dataset\n",
        "california_data = None"
      ],
      "metadata": {
        "id": "_Rt5evPrr-lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "california_data.head()"
      ],
      "metadata": {
        "id": "hk_HY8C6sA1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMissing values:\")\n",
        "print(california_data.isnull().sum())\n",
        "print(\"\\nBasic statistics:\")\n",
        "california_data.describe()"
      ],
      "metadata": {
        "id": "Y4mHMc6isBoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4Ô∏è‚É£ Data Preprocessing and Feature Engineering\n",
        "\n",
        "**Task**: Clean and prepare the data for neural network training.\n",
        "\n",
        "**Requirements**:\n",
        "- Handle missing values if any\n",
        "- Encode categorical variables\n",
        "- Scale numerical features\n",
        "- Split features and target\n",
        "- Create train/validation/test splits"
      ],
      "metadata": {
        "id": "Xq_LnahesDez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "california_data = california_data.copy()"
      ],
      "metadata": {
        "id": "FX5Ub5HXsC67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Handle missing values (fill with median for numerical columns)\n",
        "\n",
        "# TODO: Feature engineering - create new features - optional\n",
        "\n",
        "# TODO: Separate features from target\n",
        "\n",
        "# TODO: Encode the categorical ocean_proximity column\n",
        "\n",
        "# TODO: Scale the features for better neural network performance\n",
        "\n",
        "# TODO: Convert to numpy arrays\n",
        "\n",
        "# TODO: Split the data into train, validation, and test sets\n",
        "\n",
        "# TODO: Convert to PyTorch tensors\n"
      ],
      "metadata": {
        "id": "GXVndJKPsE5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Neural Network Architecture\n",
        "\n",
        "**Task**: Design and implement a neural network for regression.\n",
        "\n",
        "**Requirements**:\n",
        "- Create a multi-layer perceptron (MLP)\n",
        "- Use appropriate activation functions\n",
        "- Ensure proper input/output dimensions\n",
        "- Use suitable architecture for regression"
      ],
      "metadata": {
        "id": "m4jiSFY2sIgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HousePricePredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_hidden_layers):\n",
        "        super(HousePricePredictor, self).__init__()\n",
        "        # TODO: Input layer\n",
        "\n",
        "        # TODO: Hidden layers\n",
        "\n",
        "        # TODO: Output layer (single neuron for regression)\n",
        "\n",
        "        # TODO: Create sequential model\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Forward pass through the network\n",
        "        pass\n",
        "\n",
        "# TODO: Initialize the model\n",
        "\n",
        "# TODO: Test the model with a sample input\n"
      ],
      "metadata": {
        "id": "Q2a1tN9ZsLsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6Ô∏è‚É£ Loss Function and Optimizer\n",
        "\n",
        "**Task**: Set up appropriate loss function and optimizer for regression.\n",
        "\n",
        "**Requirements**:\n",
        "- Choose suitable loss function for regression\n",
        "- Initialize optimizer with hyperparameters"
      ],
      "metadata": {
        "id": "ivHv7xLHsPZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define loss function for regression\n",
        "\n",
        "# TODO: Define optimizer\n"
      ],
      "metadata": {
        "id": "n56oEu9nsQKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ Training Loop with Validation\n",
        "\n",
        "**Task**: Implement a comprehensive training loop with validation.\n",
        "\n",
        "**Requirements**:\n",
        "- Train the model for specified epochs\n",
        "- Track training and validation losses\n",
        "- Save the best model based on validation performance\n",
        "- Display training progress"
      ],
      "metadata": {
        "id": "iJmdvlxwsRN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create DataLoader for batch processing\n",
        "\n",
        "# TODO: Initialize tracking variables\n",
        "\n",
        "# TODO: Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        # TODO: Forward pass\n",
        "\n",
        "        # TODO: Backward pass and optimization\n",
        "\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            # TODO: Forward pass\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Calculate average losses\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "\n",
        "    # TODO: Print progress\n",
        "\n"
      ],
      "metadata": {
        "id": "pR_CSE9CsSMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 8Ô∏è‚É£ Model Evaluation and Testing\n",
        "\n",
        "**Task**: Evaluate the trained model on the test set and calculate regression metrics.\n",
        "\n",
        "**Requirements**:\n",
        "- Make predictions on test set\n",
        "- Calculate multiple regression metrics\n",
        "- Analyze model performance"
      ],
      "metadata": {
        "id": "b36fWgxNsaY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Set the model to eval mode\n",
        "\n",
        "# TODO: Make predictions on test set\n",
        "\n",
        "# TODO: Calculate regression metrics\n"
      ],
      "metadata": {
        "id": "1MPQ3MhSsbh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9Ô∏è‚É£ Visualization and Analysis\n",
        "\n",
        "**Task**: Create visualizations to analyze model performance and training progress.\n",
        "\n",
        "**Requirements**:\n",
        "- Plot training and validation loss curves\n",
        "- Analyze residuals"
      ],
      "metadata": {
        "id": "8WYMq4iDsc0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Plot training and validation loss curves\n",
        "\n",
        "# TODO: Plot predictions vs actual values\n",
        "\n",
        "# TODO: Show some sample predictions\n"
      ],
      "metadata": {
        "id": "OA6DrrhBsdZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Evaluation Criteria\n",
        "\n",
        "Your homework will be evaluated based on:\n",
        "\n",
        "1. **Implementation Correctness (50%)**\n",
        "   - Proper neural network architecture\n",
        "   - Correct data preprocessing and feature engineering(if any)\n",
        "   - Working training loop with validation\n",
        "   - Appropriate loss function and optimizer\n",
        "\n",
        "2. **Model Performance (25%)**\n",
        "   - Reasonable regression metrics (RMSE, MAE, R¬≤)\n",
        "   - Convergence during training\n",
        "   - Generalization to test set\n",
        "\n",
        "3. **Code Quality (25%)**\n",
        "   - Clean, readable code with comments\n",
        "   - Efficient implementation\n",
        "   - Good coding practices\n"
      ],
      "metadata": {
        "id": "CNnMiAaKsg_C"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}